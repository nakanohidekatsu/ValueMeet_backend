# app.py - æœ€é©åŒ–ç‰ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰

from fastapi import FastAPI, Depends, HTTPException, Query, status, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, ConfigDict, Field
import os
import json
import time
import logging
from openai import OpenAI
from dotenv import load_dotenv
from typing import Optional, List, Dict, Any
from datetime import datetime, date, time as datetime_time
from sqlalchemy import create_engine, text, select, func, and_, or_
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.pool import QueuePool
import redis
import asyncio
from contextlib import asynccontextmanager
import hashlib

from db_control import crud, mymodels
from db_control.create_tables import init_db
from db_control.crud import SessionLocal

# schemas.pyã‹ã‚‰å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã‚’import
from schemas import LoginRequest, LoginResponse, ResetPasswordRequest, MessageResponse

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
load_dotenv()

def get_database_url():
    """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URLã‚’å–å¾—ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    db_url = os.getenv("DATABASE_URL")
    if db_url:
        return db_url
    
    host = os.getenv("DB_HOST", "aws-0-ap-northeast-1.pooler.supabase.com")
    port = os.getenv("DB_PORT", "6543")
    database = os.getenv("DB_NAME", "postgres")
    user = os.getenv("DB_USER", "postgres.zdzdymwaessgxeojmtpb")
    password = os.getenv("DB_PASSWORD", "ValueMeet2025")
    
    return f"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}"

# SQLAlchemyè¨­å®šï¼ˆã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«æœ€é©åŒ–ï¼‰
try:
    DATABASE_URL = get_database_url()
    logger.info(f"ä½¿ç”¨ã™ã‚‹DATABASE_URL: {DATABASE_URL}")
    
    engine = create_engine(
        DATABASE_URL,
        poolclass=QueuePool,
        pool_size=10,  # ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«æ•°
        max_overflow=20,  # æœ€å¤§ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼
        pool_pre_ping=True,
        pool_recycle=3600,  # 1æ™‚é–“ã§ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³å†ä½œæˆ
        echo=False,
        connect_args={
            "connect_timeout": 10,
            "command_timeout": 30
        }
    )
    
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    logger.info("âœ… SQLAlchemyè¨­å®šå®Œäº†")
    
except Exception as e:
    logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    raise e

# Redisè¨­å®šï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ï¼‰
try:
    redis_client = redis.Redis(
        host=os.getenv('REDIS_HOST', 'localhost'),
        port=int(os.getenv('REDIS_PORT', 6379)),
        db=0,
        decode_responses=True,
        socket_connect_timeout=5,
        socket_timeout=5,
        retry_on_timeout=True
    )
    # Redisæ¥ç¶šãƒ†ã‚¹ãƒˆ
    redis_client.ping()
    logger.info("âœ… Redisæ¥ç¶šæˆåŠŸ")
    REDIS_AVAILABLE = True
except Exception as e:
    logger.warning(f"âš ï¸ Redisæ¥ç¶šå¤±æ•—: {e}")
    redis_client = None
    REDIS_AVAILABLE = False

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = None
if OPENAI_API_KEY:
    from openai import OpenAI
    client = OpenAI(api_key=OPENAI_API_KEY)
    logger.info("âœ… OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
else:
    logger.warning("âš ï¸ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

# === Pydantic ãƒ¢ãƒ‡ãƒ«ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰ ===

class UserProfileResponse(BaseModel):
    user_id: str
    name: str
    organization_id: int
    organization_name: str

class DepartmentMember(BaseModel):
    user_id: str
    name: str
    organization_name: str

class MeetingListItemOptimized(BaseModel):
    """æœ€é©åŒ–ã•ã‚ŒãŸä¼šè­°ãƒªã‚¹ãƒˆé …ç›®"""
    meeting_id: int
    title: str
    meeting_type: Optional[str] = None
    meeting_mode: Optional[str] = None
    date_time: str
    end_time: Optional[str] = None
    name: str = ""  # ä½œæˆè€…å
    organization_name: str = ""  # ä½œæˆè€…çµ„ç¹”å
    role_type: Optional[str] = None
    purpose: Optional[str] = None
    status: Optional[str] = "scheduled"
    participants: int = 0
    rule_violation: Optional[bool] = False
    created_by: Optional[str] = None
    agenda: Optional[List[str]] = None
    meeting_cost: Optional[float] = None  # ä¼šè­°ã‚³ã‚¹ãƒˆ

class MeetingBatchRequest(BaseModel):
    """ä¸€æ‹¬å–å¾—ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    user_id: str
    filter_type: str = "my"  # my, department, member
    selected_member: Optional[str] = None
    search_query: Optional[str] = ""
    meeting_type: Optional[str] = None
    period_type: Optional[str] = "week"
    current_date: Optional[str] = None
    limit: Optional[int] = 1000

class PaginatedResponse(BaseModel):
    """ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    meetings: List[MeetingListItemOptimized]
    pagination: Dict[str, Any]
    cache_info: Optional[Dict[str, Any]] = None

class PerformanceMetrics(BaseModel):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šçµæœ"""
    endpoint: str
    execution_time: float
    query_count: int
    cache_hit: bool
    timestamp: str

# === ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ===

def generate_cache_key(*args) -> str:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ"""
    content = json.dumps(args, sort_keys=True, default=str)
    return hashlib.md5(content.encode()).hexdigest()

def get_from_cache(key: str) -> Optional[Any]:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—"""
    if not REDIS_AVAILABLE:
        return None
    try:
        data = redis_client.get(key)
        return json.loads(data) if data else None
    except Exception as e:
        logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def set_to_cache(key: str, data: Any, ttl: int = 300) -> bool:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
    if not REDIS_AVAILABLE:
        return False
    try:
        redis_client.setex(key, ttl, json.dumps(data, default=str))
        return True
    except Exception as e:
        logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def calculate_meeting_cost(participants: int, start_time: str, end_time: str) -> float:
    """ä¼šè­°ã‚³ã‚¹ãƒˆè¨ˆç®—"""
    try:
        if not start_time or not end_time or participants == 0:
            return 0.0
        
        start = datetime.strptime(f"2000-01-01 {start_time}", "%Y-%m-%d %H:%M")
        end = datetime.strptime(f"2000-01-01 {end_time}", "%Y-%m-%d %H:%M")
        duration_hours = (end - start).total_seconds() / 3600
        
        if duration_hours <= 0:
            return 0.0
        
        return participants * 5000 * duration_hours
    except Exception:
        return 0.0

# === ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ ===

def monitor_performance(endpoint_name: str):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = await func(*args, **kwargs)
                execution_time = time.time() - start_time
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°
                logger.info(f"[PERF] {endpoint_name}: {execution_time:.3f}s")
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜ï¼ˆRedisåˆ©ç”¨å¯èƒ½æ™‚ï¼‰
                if REDIS_AVAILABLE:
                    metrics = PerformanceMetrics(
                        endpoint=endpoint_name,
                        execution_time=execution_time,
                        query_count=1,  # å®Ÿéš›ã®ã‚¯ã‚¨ãƒªæ•°ã‚’è¨ˆæ¸¬ã™ã‚‹å ´åˆã¯æ‹¡å¼µ
                        cache_hit=False,  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæƒ…å ±
                        timestamp=datetime.now().isoformat()
                    )
                    redis_client.lpush(
                        "performance_metrics", 
                        metrics.json()
                    )
                    redis_client.ltrim("performance_metrics", 0, 1000)  # æœ€æ–°1000ä»¶ä¿æŒ
                
                return result
            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(f"[ERROR] {endpoint_name}: {execution_time:.3f}s - {str(e)}")
                raise
        return wrapper
    return decorator

# === ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–é–¢æ•° ===

async def ensure_database_indexes(db: Session):
    """å¿…è¦ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç¢ºå®Ÿã«ä½œæˆ"""
    indexes = [
        # ä¼šè­°ãƒ†ãƒ¼ãƒ–ãƒ«
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_meetings_created_by_date ON meetings(created_by, date_time DESC)",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_meetings_date_time ON meetings(date_time DESC)",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_meetings_status ON meetings(status)",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_meetings_type ON meetings(meeting_type)",
        
        # å‚åŠ è€…ãƒ†ãƒ¼ãƒ–ãƒ«
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_participants_meeting_id ON participants(meeting_id)",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_participants_user_id ON participants(user_id)",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_participants_user_meeting ON participants(user_id, meeting_id)",
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_organization ON users(organization_id)",
        
        # ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ãƒ†ãƒ¼ãƒ–ãƒ«
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_agendas_meeting_id ON agendas(meeting_id)",
        
        # è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_meetings_creator_org_date ON meetings(created_by) INCLUDE (date_time, status, meeting_type)"
    ]
    
    for index_sql in indexes:
        try:
            await asyncio.to_thread(db.execute, text(index_sql))
            await asyncio.to_thread(db.commit)
            logger.info(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¢ºèª/ä½œæˆ: {index_sql.split()[-1]}")
        except Exception as e:
            logger.warning(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¹ã‚­ãƒƒãƒ—: {e}")
            await asyncio.to_thread(db.rollback)

# === ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ– ===

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†"""
    # èµ·å‹•æ™‚
    logger.info("ğŸš€ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
    try:
        init_db()
        logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    try:
        db = SessionLocal()
        await ensure_database_indexes(db)
        db.close()
        logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¢ºèªå®Œäº†")
    except Exception as e:
        logger.error(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
    if REDIS_AVAILABLE:
        try:
            redis_client.flushdb()
            logger.info("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Œäº†")
        except Exception as e:
            logger.warning(f"âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å¤±æ•—: {e}")
    
    yield
    
    # çµ‚äº†æ™‚
    logger.info("â¹ï¸ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†")

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ
app = FastAPI(
    title="Meeting Management API - Optimized",
    version="2.0.0",
    description="é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¼šè­°ç®¡ç†API",
    lifespan=lifespan
)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ ===
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# === èªè¨¼ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆæ—¢å­˜ã¨åŒã˜ï¼‰ ===

@app.post("/auth/login", response_model=LoginResponse)
async def login(request: LoginRequest, db: Session = Depends(get_db)):
    """ãƒ­ã‚°ã‚¤ãƒ³èªè¨¼"""
    try:
        query = text("""
            SELECT u.user_id, u.name, u.email, u.organization_id, u.password, 
                   COALESCE(o.organization_name, '') as organization_name
            FROM users u
            LEFT JOIN organizations o ON u.organization_id = o.organization_id
            WHERE u.user_id = :user_id
        """)
        
        result = db.execute(query, {"user_id": request.user_id})
        user = result.fetchone()
        
        if not user or user.password != request.password:
            raise HTTPException(status_code=401, detail="èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        return LoginResponse(
            user_id=user.user_id,
            name=user.name,
            email=user.email,
            organization_id=user.organization_id or 0,
            organization_name=user.organization_name or ""
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail="ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")

# === æœ€é©åŒ–ã•ã‚ŒãŸä¼šè­°ç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ===

@app.post("/meeting_list_optimized", response_model=List[MeetingListItemOptimized])
@monitor_performance("meeting_list_optimized")
async def get_meeting_list_optimized(
    request: MeetingBatchRequest,
    db: Session = Depends(get_db)
):
    """
    æœ€é©åŒ–ã•ã‚ŒãŸä¼šè­°ä¸€è¦§å–å¾—API
    - å˜ä¸€ã‚¯ã‚¨ãƒªã§å…¨ãƒ‡ãƒ¼ã‚¿å–å¾—
    - N+1å•é¡Œè§£æ±º
    - ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ã
    """
    try:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ
        cache_key = f"meetings_opt:{generate_cache_key(request.dict())}"
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        cached_data = get_from_cache(cache_key)
        if cached_data:
            logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {cache_key}")
            return [MeetingListItemOptimized(**item) for item in cached_data]
        
        # æœ€é©åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªï¼ˆå˜ä¸€ã‚¯ã‚¨ãƒªã§å…¨ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼‰
        base_query = text("""
            WITH meeting_participants AS (
                SELECT 
                    meeting_id,
                    COUNT(*) as participant_count
                FROM participants 
                GROUP BY meeting_id
            ),
            user_meetings AS (
                SELECT DISTINCT m.meeting_id
                FROM meetings m
                LEFT JOIN participants p ON m.meeting_id = p.meeting_id
                WHERE 
                    CASE 
                        WHEN :filter_type = 'my' THEN 
                            (m.created_by = :user_id OR p.user_id = :user_id)
                        WHEN :filter_type = 'department' THEN 
                            EXISTS (
                                SELECT 1 FROM users creator 
                                WHERE creator.user_id = m.created_by 
                                AND creator.organization_id = (
                                    SELECT organization_id FROM users WHERE user_id = :user_id
                                )
                            )
                        WHEN :filter_type = 'member' AND :selected_member IS NOT NULL THEN 
                            (m.created_by = :selected_member OR p.user_id = :selected_member)
                        ELSE TRUE
                    END
            )
            SELECT 
                m.meeting_id,
                m.title,
                m.meeting_type,
                m.meeting_mode,
                m.date_time,
                m.end_time,
                m.status,
                m.rule_violation,
                m.created_by,
                creator.name as creator_name,
                creator_org.organization_name,
                COALESCE(mp.participant_count, 0) as participant_count,
                a.purpose,
                CASE 
                    WHEN a.topic IS NOT NULL THEN 
                        ARRAY[a.topic]
                    ELSE 
                        ARRAY[]::text[]
                END as agenda_topics
            FROM meetings m
            INNER JOIN user_meetings um ON m.meeting_id = um.meeting_id
            LEFT JOIN users creator ON m.created_by = creator.user_id
            LEFT JOIN organizations creator_org ON creator.organization_id = creator_org.organization_id
            LEFT JOIN meeting_participants mp ON m.meeting_id = mp.meeting_id
            LEFT JOIN agendas a ON m.meeting_id = a.meeting_id
            WHERE 
                (:search_query = '' OR 
                 m.title ILIKE :search_pattern OR 
                 a.purpose ILIKE :search_pattern OR
                 creator.name ILIKE :search_pattern)
                AND (:meeting_type IS NULL OR m.meeting_type = :meeting_type)
            ORDER BY m.date_time DESC
            LIMIT :limit
        """)
        
        params = {
            'user_id': request.user_id,
            'filter_type': request.filter_type,
            'selected_member': request.selected_member,
            'search_query': request.search_query or '',
            'search_pattern': f'%{request.search_query or ""}%',
            'meeting_type': request.meeting_type if request.meeting_type != 'all' else None,
            'limit': min(request.limit or 1000, 1000)
        }
        
        # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
        start_time = time.time()
        result = db.execute(base_query, params)
        meetings = result.fetchall()
        query_time = time.time() - start_time
        
        logger.info(f"ã‚¯ã‚¨ãƒªå®Ÿè¡Œæ™‚é–“: {query_time:.3f}s, å–å¾—ä»¶æ•°: {len(meetings)}")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
        response_data = []
        for meeting in meetings:
            # ä¼šè­°ã‚³ã‚¹ãƒˆè¨ˆç®—
            meeting_cost = 0.0
            if meeting.end_time:
                start_time_str = meeting.date_time.strftime("%H:%M")
                end_time_str = meeting.end_time.strftime("%H:%M")
                meeting_cost = calculate_meeting_cost(
                    meeting.participant_count + 1,  # +1 for facilitator
                    start_time_str,
                    end_time_str
                )
            
            meeting_data = MeetingListItemOptimized(
                meeting_id=meeting.meeting_id,
                title=meeting.title,
                meeting_type=meeting.meeting_type,
                meeting_mode=meeting.meeting_mode,
                date_time=meeting.date_time.strftime("%Y-%m-%dT%H:%M:00"),
                end_time=meeting.end_time.strftime("%H:%M") if meeting.end_time else None,
                name=meeting.creator_name or "",
                organization_name=meeting.organization_name or "",
                role_type=None,  # å¿…è¦ã«å¿œã˜ã¦å¾Œã§æ‹¡å¼µ
                purpose=meeting.purpose,
                status=meeting.status or "scheduled",
                participants=meeting.participant_count or 0,
                rule_violation=meeting.rule_violation or False,
                created_by=meeting.created_by,
                agenda=meeting.agenda_topics or [],
                meeting_cost=meeting_cost
            )
            response_data.append(meeting_data)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼ˆ5åˆ†é–“ï¼‰
        cache_data = [item.dict() for item in response_data]
        set_to_cache(cache_key, cache_data, ttl=300)
        
        logger.info(f"ä¼šè­°ä¸€è¦§å–å¾—å®Œäº†: {len(response_data)}ä»¶")
        return response_data
        
    except Exception as e:
        logger.error(f"æœ€é©åŒ–ä¼šè­°ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=f"ä¼šè­°ä¸€è¦§å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

@app.get("/meeting_list_paginated", response_model=PaginatedResponse)
@monitor_performance("meeting_list_paginated")
async def get_meeting_list_paginated(
    user_id: str = Query(...),
    page: int = Query(0, ge=0),
    limit: int = Query(20, ge=1, le=100),
    filter_type: str = Query("my"),
    search_query: Optional[str] = Query(""),
    meeting_type: Optional[str] = Query(None),
    db: Session = Depends(get_db)
):
    """ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œã®ä¼šè­°ä¸€è¦§API"""
    try:
        offset = page * limit
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
        cache_key = f"meetings_page:{generate_cache_key(user_id, page, limit, filter_type, search_query, meeting_type)}"
        cached_data = get_from_cache(cache_key)
        
        if cached_data:
            return PaginatedResponse(**cached_data, cache_info={"hit": True, "key": cache_key})
        
        # ä»¶æ•°å–å¾—ã‚¯ã‚¨ãƒª
        count_query = text("""
            SELECT COUNT(DISTINCT m.meeting_id)
            FROM meetings m
            LEFT JOIN users creator ON m.created_by = creator.user_id
            LEFT JOIN participants p ON m.meeting_id = p.meeting_id
            LEFT JOIN agendas a ON m.meeting_id = a.meeting_id
            WHERE (m.created_by = :user_id OR p.user_id = :user_id)
            AND (:search_query = '' OR 
                 m.title ILIKE :search_pattern OR 
                 a.purpose ILIKE :search_pattern)
            AND (:meeting_type IS NULL OR m.meeting_type = :meeting_type)
        """)
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¯ã‚¨ãƒªï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
        data_query = text("""
            WITH meeting_data AS (
                SELECT DISTINCT
                    m.meeting_id,
                    m.title,
                    m.meeting_type,
                    m.meeting_mode,
                    m.date_time,
                    m.end_time,
                    m.status,
                    m.rule_violation,
                    m.created_by,
                    creator.name as creator_name,
                    creator_org.organization_name,
                    (SELECT COUNT(*) FROM participants p2 WHERE p2.meeting_id = m.meeting_id) as participant_count,
                    a.purpose
                FROM meetings m
                LEFT JOIN users creator ON m.created_by = creator.user_id
                LEFT JOIN organizations creator_org ON creator.organization_id = creator_org.organization_id
                LEFT JOIN participants p ON m.meeting_id = p.meeting_id
                LEFT JOIN agendas a ON m.meeting_id = a.meeting_id
                WHERE (m.created_by = :user_id OR p.user_id = :user_id)
                AND (:search_query = '' OR 
                     m.title ILIKE :search_pattern OR 
                     a.purpose ILIKE :search_pattern)
                AND (:meeting_type IS NULL OR m.meeting_type = :meeting_type)
            )
            SELECT * FROM meeting_data
            ORDER BY date_time DESC
            LIMIT :limit OFFSET :offset
        """)
        
        params = {
            'user_id': user_id,
            'search_query': search_query or '',
            'search_pattern': f'%{search_query or ""}%',
            'meeting_type': meeting_type if meeting_type != 'all' else None,
            'limit': limit,
            'offset': offset
        }
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        total_count = db.execute(count_query, params).scalar()
        meetings = db.execute(data_query, params).fetchall()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹ç¯‰
        meeting_list = []
        for m in meetings:
            meeting_cost = 0.0
            if m.end_time:
                start_time_str = m.date_time.strftime("%H:%M")
                end_time_str = m.end_time.strftime("%H:%M")
                meeting_cost = calculate_meeting_cost(
                    m.participant_count + 1,
                    start_time_str,
                    end_time_str
                )
            
            meeting_list.append(MeetingListItemOptimized(
                meeting_id=m.meeting_id,
                title=m.title,
                meeting_type=m.meeting_type,
                meeting_mode=m.meeting_mode,
                date_time=m.date_time.strftime("%Y-%m-%dT%H:%M:00"),
                end_time=m.end_time.strftime("%H:%M") if m.end_time else None,
                name=m.creator_name or "",
                organization_name=m.organization_name or "",
                purpose=m.purpose,
                status=m.status or "scheduled",
                participants=m.participant_count or 0,
                rule_violation=m.rule_violation or False,
                created_by=m.created_by,
                meeting_cost=meeting_cost
            ))
        
        pagination_info = {
            "page": page,
            "limit": limit,
            "total": total_count,
            "has_next": (offset + limit) < total_count,
            "has_prev": page > 0,
            "total_pages": (total_count + limit - 1) // limit
        }
        
        response = PaginatedResponse(
            meetings=meeting_list,
            pagination=pagination_info,
            cache_info={"hit": False, "key": cache_key}
        )
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        set_to_cache(cache_key, response.dict(), ttl=180)  # 3åˆ†
        
        return response
        
    except Exception as e:
        logger.error(f"ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=f"ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

# === æ—¢å­˜APIï¼ˆäº’æ›æ€§ç¶­æŒï¼‹æœ€é©åŒ–ï¼‰ ===

@app.get("/meeting_list", response_model=List[MeetingListItemOptimized])
async def get_meeting_list_legacy(
    user_id: str = Query(...),
    start_datetime: Optional[str] = Query(None),
    end_datetime: Optional[str] = Query(None),
    organization_id: Optional[int] = Query(None),
    meeting_type: Optional[str] = Query(None),
    db: Session = Depends(get_db)
):
    """æ—¢å­˜APIï¼ˆäº’æ›æ€§ç¶­æŒï¼‹æœ€é©åŒ–ï¼‰"""
    # æ–°ã—ã„æœ€é©åŒ–APIã«è»¢é€
    request = MeetingBatchRequest(
        user_id=user_id,
        filter_type="my",
        meeting_type=meeting_type
    )
    return await get_meeting_list_optimized(request, db)

@app.get("/department_meetings", response_model=List[MeetingListItemOptimized])
async def get_department_meetings_optimized(
    organization_id: int = Query(...),
    start_datetime: Optional[str] = Query(None),
    end_datetime: Optional[str] = Query(None),
    meeting_type: Optional[str] = Query(None),
    db: Session = Depends(get_db)
):
    """éƒ¨å†…ä¼šè­°ä¸€è¦§å–å¾—APIï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    try:
        # çµ„ç¹”ã«æ‰€å±ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’1ã¤å–å¾—ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨ï¼‰
        user_query = text("SELECT user_id FROM users WHERE organization_id = :org_id LIMIT 1")
        user_result = db.execute(user_query, {"org_id": organization_id})
        user = user_result.fetchone()
        
        if not user:
            return []
        
        request = MeetingBatchRequest(
            user_id=user.user_id,
            filter_type="department",
            meeting_type=meeting_type
        )
        return await get_meeting_list_optimized(request, db)
        
    except Exception as e:
        logger.error(f"éƒ¨å†…ä¼šè­°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/member_meetings", response_model=List[MeetingListItemOptimized])
async def get_member_meetings_optimized(
    member_id: str = Query(...),
    start_datetime: Optional[str] = Query(None),
    end_datetime: Optional[str] = Query(None),
    meeting_type: Optional[str] = Query(None),
    db: Session = Depends(get_db)
):
    """æ‹…å½“è€…ä¼šè­°ä¸€è¦§å–å¾—APIï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    request = MeetingBatchRequest(
        user_id=member_id,
        filter_type="my",
        meeting_type=meeting_type
    )
    return await get_meeting_list_optimized(request, db)

@app.get("/department_members", response_model=List[DepartmentMember])
async def get_department_members_optimized(
    organization_id: int = Query(...),
    db: Session = Depends(get_db)
):
    """éƒ¨å†…ãƒ¡ãƒ³ãƒãƒ¼ä¸€è¦§å–å¾—APIï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰"""
    try:
        cache_key = f"dept_members:{organization_id}"
        cached_data = get_from_cache(cache_key)
        
        if cached_data:
            return [DepartmentMember(**item) for item in cached_data]
        
        query = text("""
            SELECT u.user_id, u.name, o.organization_name
            FROM users u
            LEFT JOIN organizations o ON u.organization_id = o.organization_id
            WHERE u.organization_id = :organization_id
            ORDER BY u.name
        """)
        
        result = db.execute(query, {"organization_id": organization_id})
        members = result.fetchall()
        
        response_data = [
            DepartmentMember(
                user_id=member.user_id,
                name=member.name,
                organization_name=member.organization_name or ""
            )
            for member in members
        ]
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ï¼ˆ10åˆ†ï¼‰
        cache_data = [item.dict() for item in response_data]
        set_to_cache(cache_key, cache_data, ttl=600)
        
        return response_data
    
    except Exception as e:
        logger.error(f"éƒ¨å†…ãƒ¡ãƒ³ãƒãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# === ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ»ç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ===

@app.get("/admin/performance-metrics")
async def get_performance_metrics(limit: int = Query(100, le=1000)):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
    if not REDIS_AVAILABLE:
        raise HTTPException(status_code=503, detail="Redis not available")
    
    try:
        metrics = redis_client.lrange("performance_metrics", 0, limit - 1)
        return [json.loads(metric) for metric in metrics]
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/admin/cache/clear")
async def clear_cache(pattern: str = Query("*")):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
    if not REDIS_AVAILABLE:
        raise HTTPException(status_code=503, detail="Redis not available")
    
    try:
        keys = redis_client.keys(pattern)
        if keys:
            redis_client.delete(*keys)
        return {"message": f"Cleared {len(keys)} cache entries", "pattern": pattern}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/admin/database-stats")
async def get_database_stats(db: Session = Depends(get_db)):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±"""
    try:
        stats_query = text("""
            SELECT 
                schemaname,
                tablename,
                n_tup_ins as inserts,
                n_tup_upd as updates,
                n_tup_del as deletes,
                n_live_tup as live_tuples,
                n_dead_tup as dead_tuples,
                last_vacuum,
                last_autovacuum,
                last_analyze,
                last_autoanalyze
            FROM pg_stat_user_tables 
            WHERE tablename IN ('meetings', 'participants', 'users', 'organizations', 'agendas')
            ORDER BY tablename
        """)
        
        result = db.execute(stats_query)
        return [dict(row) for row in result.fetchall()]
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# === ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ ===

@app.get("/health")
async def health_check():
    """è©³ç´°ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
        db = SessionLocal()
        db.execute(text("SELECT 1"))
        db.close()
        db_status = "healthy"
    except Exception as e:
        db_status = f"unhealthy: {str(e)}"
    
    # Redisæ¥ç¶šãƒ†ã‚¹ãƒˆ
    redis_status = "healthy" if REDIS_AVAILABLE else "unavailable"
    if REDIS_AVAILABLE:
        try:
            redis_client.ping()
        except Exception as e:
            redis_status = f"unhealthy: {str(e)}"
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "database": db_status,
        "redis": redis_status,
        "version": "2.0.0"
    }

@app.get("/")
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "Meeting Management API - Optimized",
        "version": "2.0.0",
        "optimizations": [
            "N+1ã‚¯ã‚¨ãƒªå•é¡Œè§£æ±º",
            "Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½",
            "ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œ",
            "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–",
            "è‡ªå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ",
            "ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«æœ€é©åŒ–"
        ],
        "endpoints": {
            "optimized": [
                "/meeting_list_optimized",
                "/meeting_list_paginated"
            ],
            "legacy_compatible": [
                "/meeting_list",
                "/department_meetings",
                "/member_meetings"
            ],
            "admin": [
                "/admin/performance-metrics",
                "/admin/cache/clear",
                "/admin/database-stats"
            ]
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    )